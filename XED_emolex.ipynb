{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,codecs\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import*\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>1, 4, 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... And I don't think we need to discuss the T...</td>\n",
       "      <td>8, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* So get up out of your bed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A confession that you hired [PERSON] ... and a...</td>\n",
       "      <td>1, 6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent  label_1\n",
       "0                                              , ...        1\n",
       "1                                                  !  1, 4, 7\n",
       "2  ... And I don't think we need to discuss the T...     8, 1\n",
       "3                        * So get up out of your bed        1\n",
       "4  A confession that you hired [PERSON] ... and a...     1, 6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ganiyuopeyemi/desktop/NLP/XED-master/AnnotatedData/en-annotated.tsv',sep='\\t',header = None, names = [\"sent\", \"label_1\"], error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17528, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"label_1\", \"label_2\"]] = df['label_1'].str.split(\",\", 1, expand=True)\n",
    "df[[\"label_2\", \"label_3\"]] = df['label_2'].str.split(\",\", 1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... And I don't think we need to discuss the T...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* So get up out of your bed</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A confession that you hired [PERSON] ... and a...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent label_1 label_2 label_3\n",
       "0                                              , ...       1    None    None\n",
       "1                                                  !       1       4       7\n",
       "2  ... And I don't think we need to discuss the T...       8       1    None\n",
       "3                        * So get up out of your bed       1    None    None\n",
       "4  A confession that you hired [PERSON] ... and a...       1       6    None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_1\"] = pd.to_numeric(df[\"label_1\"])\n",
    "df[\"label_2_fill\"] = np.where(df.label_2.isnull(), df.label_1, df.label_2)\n",
    "df[\"label_2_fill\"] = pd.to_numeric(df[\"label_2_fill\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    \n",
    "               \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    lst_text = [w.translate(table) for w in lst_text]\n",
    "    #lst_text = [stemmer.stem(w.lower()) for w in lst_text]\n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_clean\"] = df[\"sent\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, \n",
    "          lst_stopwords= lst_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_2_fill</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... And I don't think we need to discuss the T...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>and i dont think we need to discuss the trinit...</td>\n",
       "      <td>[and, i, dont, think, we, need, to, discuss, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* So get up out of your bed</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>so get up out of your bed</td>\n",
       "      <td>[so, get, up, out, of, your, bed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A confession that you hired [PERSON] ... and a...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>a confession that you hired person and are res...</td>\n",
       "      <td>[a, confession, that, you, hired, person, and,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent  label_1 label_2 label_3  \\\n",
       "0                                              , ...        1    None    None   \n",
       "1                                                  !        1       4       7   \n",
       "2  ... And I don't think we need to discuss the T...        8       1    None   \n",
       "3                        * So get up out of your bed        1    None    None   \n",
       "4  A confession that you hired [PERSON] ... and a...        1       6    None   \n",
       "\n",
       "   label_2_fill                                         text_clean  \\\n",
       "0             1                                                      \n",
       "1             4                                                      \n",
       "2             1  and i dont think we need to discuss the trinit...   \n",
       "3             1                          so get up out of your bed   \n",
       "4             6  a confession that you hired person and are res...   \n",
       "\n",
       "                                     tokenized_sents  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [and, i, dont, think, we, need, to, discuss, t...  \n",
       "3                  [so, get, up, out, of, your, bed]  \n",
       "4  [a, confession, that, you, hired, person, and,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_sents'] = df.apply(lambda row: nltk.word_tokenize(row[\"text_clean\"]), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"sent\",\"text_clean\", \"label_1\", \"label_2_fill\",\"tokenized_sents\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17528 entries, 0 to 17527\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sent             17528 non-null  object\n",
      " 1   text_clean       17528 non-null  object\n",
      " 2   label_1          17528 non-null  int64 \n",
      " 3   label_2_fill     17528 non-null  int64 \n",
      " 4   tokenized_sents  17528 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 684.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df[df[\"text_clean\"] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2_fill</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>% ? !</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sent text_clean  label_1  label_2_fill tokenized_sents\n",
       "0     , ...                   1             1              []\n",
       "1         !                   1             4              []\n",
       "3160  % ? !                   7             7              []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df[df[\"text_clean\"] == \"\"].index\n",
    "df.drop(h, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17525, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2_fill</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>... And I don't think we need to discuss the T...</td>\n",
       "      <td>and i dont think we need to discuss the trinit...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, i, dont, think, we, need, to, discuss, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* So get up out of your bed</td>\n",
       "      <td>so get up out of your bed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[so, get, up, out, of, your, bed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A confession that you hired [PERSON] ... and a...</td>\n",
       "      <td>a confession that you hired person and are res...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[a, confession, that, you, hired, person, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A dead man has one half - hour to raise his ro...</td>\n",
       "      <td>a dead man has one half hour to raise his roll...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, dead, man, has, one, half, hour, to, raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A guy that's talking about he's gonna solve al...</td>\n",
       "      <td>a guy thats talking about hes gonna solve all ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, guy, thats, talking, about, hes, gon, na, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent  \\\n",
       "0  ... And I don't think we need to discuss the T...   \n",
       "1                        * So get up out of your bed   \n",
       "2  A confession that you hired [PERSON] ... and a...   \n",
       "3  A dead man has one half - hour to raise his ro...   \n",
       "4  A guy that's talking about he's gonna solve al...   \n",
       "\n",
       "                                          text_clean  label_1  label_2_fill  \\\n",
       "0  and i dont think we need to discuss the trinit...        8             1   \n",
       "1                          so get up out of your bed        1             1   \n",
       "2  a confession that you hired person and are res...        1             6   \n",
       "3  a dead man has one half hour to raise his roll...        1             1   \n",
       "4  a guy thats talking about hes gonna solve all ...        1             1   \n",
       "\n",
       "                                     tokenized_sents  \n",
       "0  [and, i, dont, think, we, need, to, discuss, t...  \n",
       "1                  [so, get, up, out, of, your, bed]  \n",
       "2  [a, confession, that, you, hired, person, and,...  \n",
       "3  [a, dead, man, has, one, half, hour, to, raise...  \n",
       "4  [a, guy, thats, talking, about, hes, gon, na, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emotion</th>\n",
       "      <th>association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>surprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abate</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abate</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abate</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abate</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abate</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word       emotion  association\n",
       "0  abandonment      negative            1\n",
       "1  abandonment      positive            0\n",
       "2  abandonment       sadness            1\n",
       "3  abandonment      surprise            1\n",
       "4  abandonment         trust            0\n",
       "5        abate         anger            0\n",
       "6        abate  anticipation            0\n",
       "7        abate       disgust            0\n",
       "8        abate          fear            0\n",
       "9        abate           joy            0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"NRC_emotion_lexicon_list.txt\"\n",
    "emolex_df = pd.read_csv(file,  names=[\"word\", \"emotion\", \"association\"], skiprows=45, sep='\\t')\n",
    "emolex_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141775, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emolex_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_words = emolex_df.pivot(index='word', columns='emotion', values='association').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = emolex_words.columns.drop('word')\n",
    "emo_df = pd.DataFrame(0, index=df.index, columns=emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative',\n",
       "       'positive', 'sadness', 'surprise', 'trust'],\n",
       "      dtype='object', name='emotion')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>word</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abatement</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abba</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion         word  anger  anticipation  disgust  fear  joy  negative  \\\n",
       "0                NaN    0.0           0.0      0.0   0.0  0.0       0.0   \n",
       "1        abandonment    NaN           NaN      NaN   NaN  NaN       1.0   \n",
       "2              abate    0.0           0.0      0.0   0.0  0.0       0.0   \n",
       "3          abatement    0.0           0.0      0.0   0.0  0.0       0.0   \n",
       "4               abba    0.0           0.0      0.0   0.0  0.0       0.0   \n",
       "\n",
       "emotion  positive  sadness  surprise  trust  \n",
       "0             0.0      0.0       0.0    0.0  \n",
       "1             0.0      1.0       1.0    0.0  \n",
       "2             0.0      0.0       0.0    0.0  \n",
       "3             0.0      0.0       0.0    0.0  \n",
       "4             1.0      0.0       0.0    0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emolex_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for sent in df.tokenized_sents:\n",
    "    for word in sent:\n",
    "        word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130534"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8586"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14178\n"
     ]
    }
   ],
   "source": [
    "emo_words = []\n",
    "for word in emolex_words.word:\n",
    "    emo_words.append(word)\n",
    "print(len(emo_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []\n",
    "for word in word_list:\n",
    "    if word in emo_words:\n",
    "        match.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28707\n",
      "4117\n"
     ]
    }
   ],
   "source": [
    "print(len(match))\n",
    "print(len(set(match)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.95015140927091"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(set(match))/len(set(word_list)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrclex import NRCLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = []\n",
    "for row in df.text_clean:\n",
    "    my_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17525"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a lost decade but it was worth it to make your father pay for my loss'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.text_clean[11]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 2, 'sadness': 2, 'positive': 2, 'trust': 2, 'anticipation': 1, 'joy': 1, 'anger': 1, 'fear': 1}\n"
     ]
    }
   ],
   "source": [
    "text_object =  NRCLex(text)\n",
    "d = text_object.raw_emotion_scores\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "dicts = []\n",
    "neg = []\n",
    "pos = []\n",
    "fear = []\n",
    "anger = []\n",
    "disg = []\n",
    "joy = []\n",
    "anticipation = []\n",
    "trust = []\n",
    "surp = []\n",
    "sad = []\n",
    "for sent in my_list:\n",
    "    text_object =  NRCLex(sent)\n",
    "    d = text_object.raw_emotion_scores\n",
    "    for j in emotions:\n",
    "        if j not in d.keys():\n",
    "            d[j] =0\n",
    "    dicts.append(d)\n",
    "    \n",
    "for dic in dicts:\n",
    "    neg.append(dic[\"negative\"])\n",
    "    pos.append(dic[\"positive\"])\n",
    "    fear.append(dic[\"fear\"])\n",
    "    anger.append(dic[\"anger\"])\n",
    "    disg.append(dic[\"disgust\"])\n",
    "    joy.append(dic[\"joy\"])\n",
    "    anticipation.append(dic[\"anticipation\"])\n",
    "    trust.append(dic[\"trust\"])\n",
    "    surp.append(dic[\"surprise\"])\n",
    "    sad.append(dic[\"sadness\"])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17525\n",
      "17525\n",
      "17525\n",
      "17525\n",
      "17525\n",
      "17525\n",
      "17525\n",
      "17525\n",
      "17525\n",
      "17525\n"
     ]
    }
   ],
   "source": [
    "print(len(pos))\n",
    "print(len(neg))\n",
    "print(len(fear))\n",
    "print(len(anger))\n",
    "print(len(disg))\n",
    "print(len(joy))\n",
    "print(len(anticipation))\n",
    "print(len(trust))\n",
    "print(len(surp))\n",
    "print(len(sad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>disg</th>\n",
       "      <th>joy</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>surp</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and i dont think we need to discuss the trinit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so get up out of your bed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a confession that you hired person and are res...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a dead man has one half hour to raise his roll...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a guy thats talking about hes gonna solve all ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             cleaned  pos  neg  fear  anger  \\\n",
       "0  and i dont think we need to discuss the trinit...    0    0     0      0   \n",
       "1                          so get up out of your bed    0    0     0      0   \n",
       "2  a confession that you hired person and are res...    1    2     2      1   \n",
       "3  a dead man has one half hour to raise his roll...    0    0     0      0   \n",
       "4  a guy thats talking about hes gonna solve all ...    0    0     0      0   \n",
       "\n",
       "   disg  joy  anticipation  trust  surp  sad  \n",
       "0     0    0             0      0     0    0  \n",
       "1     0    0             0      0     0    0  \n",
       "2     1    0             1      1     2    2  \n",
       "3     0    0             0      0     0    0  \n",
       "4     0    0             0      0     0    0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"cleaned\"] = my_list\n",
    "data[\"pos\"] = pos\n",
    "data[\"neg\"] = neg\n",
    "data[\"fear\"] = fear\n",
    "data[\"anger\"] = anger\n",
    "data[\"disg\"] = disg\n",
    "data[\"joy\"] = joy\n",
    "data[\"anticipation\"] = anticipation\n",
    "data[\"trust\"] = trust\n",
    "data[\"surp\"] = surp\n",
    "data[\"sad\"] = sad\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sum\"] = data.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7667\n",
       "1     2149\n",
       "2     1738\n",
       "3     1543\n",
       "5     1302\n",
       "4     1150\n",
       "6      666\n",
       "7      377\n",
       "8      282\n",
       "9      212\n",
       "10     138\n",
       "11      93\n",
       "12      71\n",
       "13      48\n",
       "15      27\n",
       "16      20\n",
       "14      18\n",
       "17       8\n",
       "19       5\n",
       "18       5\n",
       "22       4\n",
       "20       1\n",
       "21       1\n",
       "Name: sum, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sum\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label_1\"] = df.label_1\n",
    "data[\"label_2_fill\"] = df.label_2_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data[\"sum\"] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>disg</th>\n",
       "      <th>joy</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>surp</th>\n",
       "      <th>sad</th>\n",
       "      <th>sum</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2_fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a confession that you hired person and are res...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a guy who was a pain in the neck even before i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a hundred of these are produced every day and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a little restraint</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a lost decade but it was worth it to make your...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             cleaned  pos  neg  fear  anger  \\\n",
       "0  a confession that you hired person and are res...    1    2     2      1   \n",
       "1  a guy who was a pain in the neck even before i...    0    1     1      0   \n",
       "2  a hundred of these are produced every day and ...    1    1     1      1   \n",
       "3                                 a little restraint    1    0     0      0   \n",
       "4  a lost decade but it was worth it to make your...    2    2     1      1   \n",
       "\n",
       "   disg  joy  anticipation  trust  surp  sad  sum  label_1  label_2_fill  \n",
       "0     1    0             1      1     2    2   13        1             6  \n",
       "1     0    0             0      0     0    1    3        1             1  \n",
       "2     1    0             1      0     0    1    7        1             3  \n",
       "3     0    0             0      0     0    0    1        1             1  \n",
       "4     0    1             1      2     0    2   12        1             1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9858, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pos_target\"] = data[\"joy\"] + data[\"anticipation\"] + data[\"trust\"]\n",
    "data[\"neg_target\"] = data[\"fear\"] + data[\"anger\"] + data[\"disg\"] + data[\"surp\"] + data[\"sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>disg</th>\n",
       "      <th>joy</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>surp</th>\n",
       "      <th>sad</th>\n",
       "      <th>sum</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2_fill</th>\n",
       "      <th>pos_target</th>\n",
       "      <th>neg_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a confession that you hired person and are res...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a guy who was a pain in the neck even before i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a hundred of these are produced every day and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a little restraint</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a lost decade but it was worth it to make your...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             cleaned  pos  neg  fear  anger  \\\n",
       "0  a confession that you hired person and are res...    1    2     2      1   \n",
       "1  a guy who was a pain in the neck even before i...    0    1     1      0   \n",
       "2  a hundred of these are produced every day and ...    1    1     1      1   \n",
       "3                                 a little restraint    1    0     0      0   \n",
       "4  a lost decade but it was worth it to make your...    2    2     1      1   \n",
       "\n",
       "   disg  joy  anticipation  trust  surp  sad  sum  label_1  label_2_fill  \\\n",
       "0     1    0             1      1     2    2   13        1             6   \n",
       "1     0    0             0      0     0    1    3        1             1   \n",
       "2     1    0             1      0     0    1    7        1             3   \n",
       "3     0    0             0      0     0    0    1        1             1   \n",
       "4     0    1             1      2     0    2   12        1             1   \n",
       "\n",
       "   pos_target  neg_target  \n",
       "0           2           8  \n",
       "1           0           2  \n",
       "2           1           4  \n",
       "3           0           0  \n",
       "4           4           4  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarity based on the sum of positive emotions vs the sum of the negative emotions (XED vs EMOLEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_1 vs sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff = data.copy()\n",
    "data_diff.drop(data_diff.loc[data_diff[\"pos_target\"]==data_diff[\"neg_target\"]].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8151, 16)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff = data_diff.reset_index(drop=True)\n",
    "data_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff[\"target\"] = data_diff[[\"pos_target\", \"neg_target\"]].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff = data_diff[[\"cleaned\", \"label_1\", \"label_2_fill\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff[\"label_polarity\"] = data_diff[\"label_1\"].map({1:0, 2:1, 3:0, 4:0, 5:1, 6:0, 7:0, 8:1})\n",
    "data_diff[\"label_polarity_2\"] = data_diff[\"label_2_fill\"].map({1:0, 2:1, 3:0, 4:0, 5:1, 6:0, 7:0, 8:1})\n",
    "data_diff[\"target_polarity\"] = data_diff[\"target\"].map({'neg_target':0, 'pos_target':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_diff[\"cleaned\"]\n",
    "y_target = data_diff[\"target_polarity\"]\n",
    "y_label = data_diff[\"label_polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4850\n",
       "1    3301\n",
       "Name: label_polarity, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff.label_polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4152\n",
       "0    3999\n",
       "Name: target_polarity, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff.target_polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naïve Bayes:\n",
    "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# LogisticRegression \n",
    "text_clf_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_t, y_test_t, y_train_l, y_test_l = train_test_split(X, y_target, y_label, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of MultinomialNB EmoLex Polarity (sums vs label_1)\n",
      "Confusion Matrix \n",
      " [[818 633]\n",
      " [281 714]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64      1451\n",
      "           1       0.53      0.72      0.61       995\n",
      "\n",
      "    accuracy                           0.63      2446\n",
      "   macro avg       0.64      0.64      0.63      2446\n",
      "weighted avg       0.66      0.63      0.63      2446\n",
      "\n",
      "Accuracy Score:  0.6263286999182338\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of MultinomialNB EmoLex Polarity (sums vs label_1)\")\n",
    "text_clf_nb.fit(X_train, y_train_t)\n",
    "predictions = text_clf_nb.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LinearSVC EmoLex Polarity (sums vs label_1)\n",
      "Confusion Matrix \n",
      " [[872 579]\n",
      " [309 686]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66      1451\n",
      "           1       0.54      0.69      0.61       995\n",
      "\n",
      "    accuracy                           0.64      2446\n",
      "   macro avg       0.64      0.65      0.63      2446\n",
      "weighted avg       0.66      0.64      0.64      2446\n",
      "\n",
      "Accuracy Score:  0.6369582992641046\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LinearSVC EmoLex Polarity (sums vs label_1)\")\n",
    "text_clf_lsvc.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\", metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LogisticRegression EmoLex Polarity (sums vs label_1)\n",
      "Confusion Matrix \n",
      " [[855 596]\n",
      " [317 678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.65      1451\n",
      "           1       0.53      0.68      0.60       995\n",
      "\n",
      "    accuracy                           0.63      2446\n",
      "   macro avg       0.63      0.64      0.62      2446\n",
      "weighted avg       0.65      0.63      0.63      2446\n",
      "\n",
      "Accuracy Score 0.6267375306623058\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LogisticRegression EmoLex Polarity (sums vs label_1)\")\n",
    "text_clf_lr.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lr.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score\", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_2 vs sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = data_diff[\"label_polarity_2\"]\n",
    "X_train, X_test, y_train_t, y_test_t, y_train_l, y_test_l = train_test_split(X, y_target, y_label, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5005\n",
       "1    3146\n",
       "Name: label_polarity_2, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff.label_polarity_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of MultinomialNB EmoLex Polarity (sums vs label_2)\n",
      "Confusion Matrix \n",
      " [[832 662]\n",
      " [267 685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.56      0.64      1494\n",
      "           1       0.51      0.72      0.60       952\n",
      "\n",
      "    accuracy                           0.62      2446\n",
      "   macro avg       0.63      0.64      0.62      2446\n",
      "weighted avg       0.66      0.62      0.62      2446\n",
      "\n",
      "Accuracy Score:  0.6201962387571546\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of MultinomialNB EmoLex Polarity (sums vs label_2)\")\n",
    "text_clf_nb.fit(X_train, y_train_t)\n",
    "predictions = text_clf_nb.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LinearSVC EmoLex Polarity (sums vs label_2)\n",
      "Confusion Matrix \n",
      " [[884 610]\n",
      " [297 655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66      1494\n",
      "           1       0.52      0.69      0.59       952\n",
      "\n",
      "    accuracy                           0.63      2446\n",
      "   macro avg       0.63      0.64      0.63      2446\n",
      "weighted avg       0.66      0.63      0.63      2446\n",
      "\n",
      "Accuracy Score:  0.6291905151267375\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LinearSVC EmoLex Polarity (sums vs label_2)\")\n",
    "text_clf_lsvc.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\", metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LogisticRegression EmoLex Polarity (sums vs label_2)\n",
      "Confusion Matrix \n",
      " [[869 625]\n",
      " [303 649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65      1494\n",
      "           1       0.51      0.68      0.58       952\n",
      "\n",
      "    accuracy                           0.62      2446\n",
      "   macro avg       0.63      0.63      0.62      2446\n",
      "weighted avg       0.65      0.62      0.63      2446\n",
      "\n",
      "Accuracy Score 0.6206050695012265\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LogisticRegression EmoLex Polarity (sums vs label_2)\")\n",
    "text_clf_lr.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lr.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score\", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarity based on emolex (neg, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_1 vs emolex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8206, 16)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff_1 = data.copy()\n",
    "data_diff_1.drop(data_diff.loc[data_diff_1[\"pos\"]==data_diff_1[\"neg\"]].index, inplace=True)\n",
    "data_diff_1 = data_diff_1.reset_index(drop=True)\n",
    "data_diff_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_1[\"target\"] = data_diff_1[[\"pos\", \"neg\"]].idxmax(axis=1)\n",
    "data_diff_1 = data_diff_1[[\"cleaned\", \"label_1\", \"label_2_fill\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_1[\"label_polarity\"] = data_diff_1[\"label_1\"].map({1:0, 2:1, 3:0, 4:0, 5:1, 6:0, 7:0, 8:1})\n",
    "data_diff_1[\"label_polarity_2\"] = data_diff_1[\"label_2_fill\"].map({1:0, 2:1, 3:0, 4:0, 5:1, 6:0, 7:0, 8:1})\n",
    "data_diff_1[\"target_polarity\"] = data_diff_1[\"target\"].map({'neg':0, 'pos':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_diff_1[\"cleaned\"]\n",
    "y_target = data_diff_1[\"target_polarity\"]\n",
    "y_label = data_diff_1[\"label_polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_t, y_test_t, y_train_l, y_test_l = train_test_split(X, y_target, y_label, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4851\n",
       "1    3355\n",
       "Name: label_polarity, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff_1.label_polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4461\n",
       "0    3745\n",
       "Name: target_polarity, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff_1.target_polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of MultinomialNB EmoLex Polarity 1\n",
      "Confusion Matrix \n",
      " [[752 714]\n",
      " [204 792]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.51      0.62      1466\n",
      "           1       0.53      0.80      0.63       996\n",
      "\n",
      "    accuracy                           0.63      2462\n",
      "   macro avg       0.66      0.65      0.63      2462\n",
      "weighted avg       0.68      0.63      0.63      2462\n",
      "\n",
      "Accuracy Score:  0.6271324126726239\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of MultinomialNB EmoLex Polarity 1\")\n",
    "text_clf_nb.fit(X_train, y_train_t)\n",
    "predictions = text_clf_nb.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LinearSVC EmoLex Polarity 1\n",
      "Confusion Matrix \n",
      " [[831 635]\n",
      " [238 758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      1466\n",
      "           1       0.54      0.76      0.63       996\n",
      "\n",
      "    accuracy                           0.65      2462\n",
      "   macro avg       0.66      0.66      0.65      2462\n",
      "weighted avg       0.68      0.65      0.65      2462\n",
      "\n",
      "Accuracy Score:  0.6454102355808286\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LinearSVC EmoLex Polarity 1\")\n",
    "text_clf_lsvc.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\", metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LogisticRegression EmoLex Polarity 1\n",
      "Confusion Matrix \n",
      " [[774 692]\n",
      " [233 763]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.53      0.63      1466\n",
      "           1       0.52      0.77      0.62       996\n",
      "\n",
      "    accuracy                           0.62      2462\n",
      "   macro avg       0.65      0.65      0.62      2462\n",
      "weighted avg       0.67      0.62      0.62      2462\n",
      "\n",
      "Accuracy Score 0.624289195775792\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LogisticRegression EmoLex Polarity 1\")\n",
    "text_clf_lr.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lr.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score\", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_2 vs emolex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = data_diff_1[\"label_polarity_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4851\n",
       "1    3355\n",
       "Name: label_polarity, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff_1.label_polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_t, y_test_t, y_train_l, y_test_l = train_test_split(X, y_target, y_label, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of MultinomialNB EmoLex Polarity 2\n",
      "Confusion Matrix \n",
      " [[766 751]\n",
      " [190 755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62      1517\n",
      "           1       0.50      0.80      0.62       945\n",
      "\n",
      "    accuracy                           0.62      2462\n",
      "   macro avg       0.65      0.65      0.62      2462\n",
      "weighted avg       0.69      0.62      0.62      2462\n",
      "\n",
      "Accuracy Score:  0.6177904142973193\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of MultinomialNB EmoLex Polarity 2\")\n",
    "text_clf_nb.fit(X_train, y_train_t)\n",
    "predictions = text_clf_nb.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LinearSVC EmoLex Polarity 2\n",
      "Confusion Matrix \n",
      " [[847 670]\n",
      " [222 723]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.56      0.66      1517\n",
      "           1       0.52      0.77      0.62       945\n",
      "\n",
      "    accuracy                           0.64      2462\n",
      "   macro avg       0.66      0.66      0.64      2462\n",
      "weighted avg       0.69      0.64      0.64      2462\n",
      "\n",
      "Accuracy Score:  0.6376929325751421\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LinearSVC EmoLex Polarity 2\")\n",
    "text_clf_lsvc.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\", metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of LogisticRegression EmoLex Polarity 1\n",
      "Confusion Matrix \n",
      " [[788 729]\n",
      " [219 726]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.52      0.62      1517\n",
      "           1       0.50      0.77      0.61       945\n",
      "\n",
      "    accuracy                           0.61      2462\n",
      "   macro avg       0.64      0.64      0.61      2462\n",
      "weighted avg       0.67      0.61      0.62      2462\n",
      "\n",
      "Accuracy Score 0.6149471974004874\n"
     ]
    }
   ],
   "source": [
    "print(\"Report of LogisticRegression EmoLex Polarity 1\")\n",
    "text_clf_lr.fit(X_train, y_train_t)\n",
    "predictions = text_clf_lr.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(y_test_l,predictions))\n",
    "print(metrics.classification_report(y_test_l,predictions))\n",
    "print(\"Accuracy Score\", metrics.accuracy_score(y_test_l,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
